// @ts-nocheck
/**
 * ab-test-manager - Gestion des tests A/B
 *
 * ðŸ”’ SÃ‰CURISÃ‰: Auth admin + Rate limit 10/min + CORS restrictif
 */
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.39.3";
import { authorizeRole } from '../_shared/auth.ts';
import { cors, preflightResponse, rejectCors } from '../_shared/cors.ts';
import { enforceEdgeRateLimit, buildRateLimitResponse } from '../_shared/rate-limit.ts';

serve(async (req) => {
  const corsResult = cors(req);
  const corsHeaders = {
    ...corsResult.headers,
    'X-Content-Type-Options': 'nosniff',
    'X-Frame-Options': 'DENY',
  };

  if (req.method === 'OPTIONS') {
    return preflightResponse(corsResult);
  }

  if (!corsResult.allowed) {
    return rejectCors(corsResult);
  }

  const { user, status } = await authorizeRole(req, ['admin']);
  if (!user) {
    return new Response(JSON.stringify({ error: 'Unauthorized' }), {
      status,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }

  const rateLimit = await enforceEdgeRateLimit(req, {
    route: 'ab-test-manager',
    userId: user.id,
    limit: 10,
    windowMs: 60_000,
    description: 'A/B test manager - Admin only',
  });

  if (!rateLimit.allowed) {
    return buildRateLimitResponse(rateLimit, corsHeaders, {
      errorCode: 'rate_limit_exceeded',
      message: `Trop de requÃªtes. RÃ©essayez dans ${rateLimit.retryAfterSeconds}s.`,
    });
  }

  try {
    const { action, test_id } = await req.json();

    if (!action || (action !== 'analyze_all' && !test_id)) {
      return new Response(
        JSON.stringify({ error: 'action et test_id requis' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const supabase = createClient(supabaseUrl, supabaseKey);

    if (action === 'analyze_all') {
      // Analyser tous les tests en cours
      const { data: runningTests, error: testsError } = await supabase
        .from('ab_test_configurations')
        .select('*')
        .eq('status', 'running');

      if (testsError) throw testsError;

      const analysisResults = [];
      for (const test of runningTests || []) {
        const result = await analyzeTest(supabase, test.id);
        analysisResults.push(result);
      }

      return new Response(
        JSON.stringify({ 
          analyzed_tests: analysisResults.length,
          results: analysisResults 
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    if (action === 'analyze') {
      const result = await analyzeTest(supabase, test_id);
      return new Response(
        JSON.stringify(result),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    if (action === 'select_winner') {
      const result = await selectWinner(supabase, test_id);
      return new Response(
        JSON.stringify(result),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    return new Response(
      JSON.stringify({ error: 'Action non reconnue' }),
      { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error) {
    console.error('AB test manager error:', error);
    return new Response(
      JSON.stringify({ error: error.message || 'Erreur AB test manager' }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});

async function analyzeTest(supabase: any, testId: string) {
  // RÃ©cupÃ©rer le test
  const { data: test, error: testError } = await supabase
    .from('ab_test_configurations')
    .select('*')
    .eq('id', testId)
    .single();

  if (testError || !test) {
    throw new Error('Test non trouvÃ©');
  }

  // RÃ©cupÃ©rer les rÃ©sultats
  const { data: results, error: resultsError } = await supabase
    .from('ab_test_results')
    .select('*')
    .eq('test_id', testId);

  if (resultsError) throw resultsError;

  // Calculer les mÃ©triques pour chaque variant
  const controlResults = results?.filter(r => r.variant === 'control') || [];
  const variantResults = results?.filter(r => r.variant === 'variant') || [];

  const controlMetrics = calculateMetrics(controlResults);
  const variantMetrics = calculateMetrics(variantResults);

  // Calculer la significativitÃ© statistique
  const sampleSize = Math.min(controlResults.length, variantResults.length);
  const hasMinSample = sampleSize >= (test.min_sample_size || 100);

  let winner = 'inconclusive';
  let confidence = 0;

  if (hasMinSample) {
    // Test de significativitÃ© (approximation simple)
    const resolutionRateDiff = Math.abs(variantMetrics.resolution_rate - controlMetrics.resolution_rate);
    const avgResolutionTimeDiff = Math.abs(variantMetrics.avg_resolution_time - controlMetrics.avg_resolution_time);

    // Score combinÃ© (plus le taux de rÃ©solution est Ã©levÃ© et le temps court, mieux c'est)
    const controlScore = controlMetrics.resolution_rate * 100 - controlMetrics.avg_resolution_time / 60;
    const variantScore = variantMetrics.resolution_rate * 100 - variantMetrics.avg_resolution_time / 60;

    const scoreDiff = Math.abs(variantScore - controlScore);
    confidence = Math.min(scoreDiff / 20, 1); // Normaliser entre 0 et 1

    if (confidence >= (test.confidence_level || 0.95)) {
      winner = variantScore > controlScore ? 'variant' : 'control';
    }
  }

  // Mettre Ã  jour le test avec les rÃ©sultats
  await supabase
    .from('ab_test_configurations')
    .update({
      metadata: {
        ...test.metadata,
        last_analysis: new Date().toISOString(),
        control_metrics: controlMetrics,
        variant_metrics: variantMetrics,
        sample_size: sampleSize,
        has_min_sample: hasMinSample,
        current_winner: winner,
        confidence
      }
    })
    .eq('id', testId);

  const isSignificant = hasMinSample && confidence >= (test.confidence_level || 0.95);
  
  // Send notification if significant
  if (isSignificant && winner !== 'inconclusive') {
    try {
      await fetch(`${Deno.env.get('SUPABASE_URL')}/functions/v1/send-notification`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${Deno.env.get('SUPABASE_ANON_KEY')}`
        },
        body: JSON.stringify({
          event_type: 'ab_test_significant',
          title: `Test A/B Significatif: ${test.name}`,
          message: `Le test "${test.name}" a atteint la significativitÃ© statistique. Le ${winner === 'control' ? 'contrÃ´le' : 'variant'} est significativement meilleur (confiance: ${(confidence * 100).toFixed(1)}%)`,
          severity: 'success',
          data: {
            'Test': test.name,
            'Gagnant': winner === 'control' ? 'ContrÃ´le' : 'Variant',
            'Confiance': `${(confidence * 100).toFixed(1)}%`,
            'Taux contrÃ´le': `${(controlMetrics.resolution_rate * 100).toFixed(1)}%`,
            'Taux variant': `${(variantMetrics.resolution_rate * 100).toFixed(1)}%`,
            'Ã‰chantillon': sampleSize.toString()
          }
        })
      });
      console.log('Notification sent for significant A/B test');
    } catch (notifError) {
      console.error('Failed to send notification:', notifError);
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // INTÃ‰GRATION PROACTIVE: DÃ©tecter rÃ©sultats nÃ©gatifs significatifs
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const performanceImprovement = ((variantScore - controlScore) / Math.abs(controlScore)) * 100;
    const isNegativeSignificant = isSignificant && performanceImprovement < -10; // -10% ou pire
    
    if (isNegativeSignificant) {
      try {
        console.log('Detected significant negative A/B test result, generating incident report...');
        await supabase.functions.invoke('generate-incident-report', {
          body: {
            title: `Test A/B NÃ©gatif Significatif: ${test.test_name}`,
            severity: performanceImprovement < -20 ? 'high' : 'medium',
            affectedSystems: ['A/B Testing System', test.variant_name],
            impactDescription: `Le test A/B "${test.test_name}" montre une dÃ©gradation significative de performance de ${performanceImprovement.toFixed(1)}% avec une confiance de ${(confidence * 100).toFixed(1)}%. Le variant ${test.variant_name} performe significativement moins bien que le contrÃ´le.`
          }
        });
        console.log('Incident report generation triggered for negative A/B test');
      } catch (incidentError) {
        console.error('Failed to generate incident report for negative test:', incidentError);
      }
    }
  }

  return {
    test_id: testId,
    test_name: test.name,
    sample_size: sampleSize,
    has_min_sample: hasMinSample,
    control_metrics: controlMetrics,
    variant_metrics: variantMetrics,
    winner,
    confidence,
    recommendation: hasMinSample 
      ? (confidence >= (test.confidence_level || 0.95) 
          ? `Le variant ${winner} est significativement meilleur (confiance: ${(confidence * 100).toFixed(1)}%)`
          : 'DiffÃ©rence non significative, continuer le test')
      : `Ã‰chantillon insuffisant (${sampleSize}/${test.min_sample_size || 100})`
  };
}

function calculateMetrics(results: any[]) {
  const total = results.length;
  if (total === 0) {
    return {
      total: 0,
      resolved: 0,
      resolution_rate: 0,
      avg_resolution_time: 0,
      avg_escalations: 0
    };
  }

  const resolved = results.filter(r => r.resolved).length;
  const avgResolutionTime = results
    .filter(r => r.resolution_time_minutes)
    .reduce((sum, r) => sum + r.resolution_time_minutes, 0) / (resolved || 1);
  const avgEscalations = results.reduce((sum, r) => sum + (r.escalation_count || 0), 0) / total;

  return {
    total,
    resolved,
    resolution_rate: resolved / total,
    avg_resolution_time: avgResolutionTime,
    avg_escalations: avgEscalations
  };
}

async function selectWinner(supabase: any, testId: string) {
  // Analyser d'abord
  const analysis = await analyzeTest(supabase, testId);

  if (analysis.winner === 'inconclusive') {
    throw new Error('Impossible de sÃ©lectionner un gagnant : rÃ©sultats non concluants');
  }

  // RÃ©cupÃ©rer le test
  const { data: test } = await supabase
    .from('ab_test_configurations')
    .select('*, control_rule_id, variant_rule_id')
    .eq('id', testId)
    .single();

  // Marquer le test comme complÃ©tÃ© avec le gagnant
  await supabase
    .from('ab_test_configurations')
    .update({
      status: 'completed',
      winner: analysis.winner,
      end_date: new Date().toISOString()
    })
    .eq('id', testId);

  // Appliquer automatiquement la rÃ¨gle gagnante
  const winningRuleId = analysis.winner === 'control' ? test.control_rule_id : test.variant_rule_id;
  const losingRuleId = analysis.winner === 'control' ? test.variant_rule_id : test.control_rule_id;

  // DÃ©sactiver la rÃ¨gle perdante si elle existe
  if (losingRuleId) {
    await supabase
      .from('alert_escalation_rules')
      .update({ is_active: false })
      .eq('id', losingRuleId);
  }

  // S'assurer que la rÃ¨gle gagnante est active
  if (winningRuleId) {
    await supabase
      .from('alert_escalation_rules')
      .update({ is_active: true })
      .eq('id', winningRuleId);
  }

  return {
    success: true,
    winner: analysis.winner,
    confidence: analysis.confidence,
    winning_rule_id: winningRuleId,
    metrics: analysis.winner === 'control' ? analysis.control_metrics : analysis.variant_metrics,
    message: `Test complÃ©tÃ© : ${analysis.winner} sÃ©lectionnÃ© et appliquÃ© automatiquement`
  };
}