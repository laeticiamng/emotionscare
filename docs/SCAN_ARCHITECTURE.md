# Architecture du Module de Scan Ã‰motionnel

## ğŸ“ Vue d'ensemble de l'architecture

Le module de scan Ã©motionnel est construit sur une architecture modulaire multi-couches permettant l'extensibilitÃ© et la maintenabilitÃ©.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Interface Utilisateur                   â”‚
â”‚         (Components React + Hooks personnalisÃ©s)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Couche de PrÃ©sentation                      â”‚
â”‚  - EnhancedEmotionScanner                               â”‚
â”‚  - EmotionalScanHub                                      â”‚
â”‚  - UnifiedEmotionCheckin                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Couche MÃ©tier (Hooks)                       â”‚
â”‚  - useEnhancedEmotionScan                               â”‚
â”‚  - useEmotionAnalysis                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Couche de Services                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Analyse   â”‚ Validation â”‚AgrÃ©gation â”‚  Utilitaires â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Couche d'Infrastructure                       â”‚
â”‚  - API Backend (Fastify)                                â”‚
â”‚  - Base de donnÃ©es (Supabase)                           â”‚
â”‚  - Stockage des mÃ©dias                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Composants principaux

### 1. Services d'analyse

#### enhancedAnalyzeService.ts
Service principal d'analyse Ã©motionnelle avec support multimodal.

**ResponsabilitÃ©s:**
- Analyse d'Ã©motions Ã  partir de texte, voix ou image
- Combinaison de multiples sources pour amÃ©liorer la prÃ©cision
- Calcul des vecteurs Ã©motionnels (VAD: Valence, Arousal, Dominance)

**Flux de traitement:**
```
Input (Text/Audio/Image)
    â†“
Preprocessing & Validation
    â†“
AI Model Analysis
    â†“
Post-processing & Smoothing
    â†“
Confidence Calculation
    â†“
Result Formatting
    â†“
Return EmotionResult
```

#### analyzeService.ts
Service simplifiÃ© pour analyses rapides.

#### emotionService.ts
Service multimodal avec fonctions spÃ©cialisÃ©es par source.

**Fonctions principales:**
```typescript
analyzeTextEmotion(text: string): Promise<EmotionAnalysis>
analyzeAudioEmotion(blob: Blob): Promise<EmotionAnalysis>
analyzeFacialEmotion(blob: Blob): Promise<EmotionAnalysis>
combineEmotionSources(...): EmotionAnalysis
```

### 2. Validation et qualitÃ©

#### scanValidation.ts
SystÃ¨me complet de validation des configurations et rÃ©sultats.

**FonctionnalitÃ©s:**
- Validation de configuration de scan
- Validation de rÃ©sultats d'Ã©motion
- Calcul de score de qualitÃ©
- Comparaison de rÃ©sultats
- Nettoyage et normalisation de donnÃ©es

**Algorithme de calcul de qualitÃ©:**
```
Quality Score =
  (Confidence * 0.4) +
  (Duration Optimality * 0.2) +
  (Multi-source Bonus * 0.2) +
  (Biometric Tracking * 0.1) +
  (Predictive Mode * 0.1)
```

### 3. AgrÃ©gation et statistiques

#### scanAggregation.ts
Moteur d'analyse avancÃ©e pour les tendances et patterns.

**Algorithmes clÃ©s:**

##### Calcul du score de bien-Ãªtre
```
Wellbeing Score (0-100) =
  (Normalized Valence * 40) +      // Ã‰motions positives vs nÃ©gatives
  (Average Confidence * 20) +       // QualitÃ© des scans
  (Emotional Stability * 20) +      // StabilitÃ© dans le temps
  (Positive Emotion Ratio * 20)     // Proportion d'Ã©motions positives
```

##### DÃ©tection de tendances
```typescript
// Algorithme de dÃ©tection de tendances
1. Diviser les rÃ©sultats en deux moitiÃ©s temporelles
2. Compter les occurrences par Ã©motion dans chaque moitiÃ©
3. Calculer le pourcentage de changement
4. Classifier: increasing, decreasing, stable (seuil Â±20%)
```

##### DÃ©tection de patterns
Analyse les Ã©motions par:
- Moment de la journÃ©e (matin, aprÃ¨s-midi, soir)
- Type de jour (semaine vs weekend)
- Transitions Ã©motionnelles frÃ©quentes

### 4. Hook React personnalisÃ©

#### useEnhancedEmotionScan
Hook principal pour l'intÃ©gration React.

**Ã‰tat gÃ©rÃ©:**
```typescript
{
  isScanning: boolean,
  scanProgress: number,
  currentResult: EmotionResult | null,
  permissions: { camera: boolean, microphone: boolean },
  scanHistory: EmotionResult[]
}
```

**Cycle de vie du scan:**
```
[Idle]
  â†“ startScan()
[Permission Check]
  â†“
[Media Stream Setup]
  â†“
[Scanning] â† Progress updates (0-100%)
  â†“
[Analysis]
  â†“
[Results Processing]
  â†“
[Cleanup & Save]
  â†“
[Idle]
```

## ğŸ¯ ModÃ¨les de donnÃ©es

### ModÃ¨le Ã©motionnel VAD

Le systÃ¨me utilise le modÃ¨le VAD (Valence-Arousal-Dominance):

```
Valence (V): -1 â† [NÃ©gatif] --- [Neutre] --- [Positif] â†’ +1
Arousal (A):  0 â† [Calme] --- [ModÃ©rÃ©] --- [ExcitÃ©] â†’ 1
Dominance (D): 0 â† [Soumis] --- [Neutre] --- [Dominant] â†’ 1
```

**Mapping Ã©motions â†’ VAD:**
```typescript
happy:     { V: +0.8, A: 0.6, D: 0.7 }
sad:       { V: -0.7, A: 0.3, D: 0.2 }
angry:     { V: -0.6, A: 0.9, D: 0.8 }
fear:      { V: -0.8, A: 0.8, D: 0.1 }
calm:      { V: +0.3, A: 0.1, D: 0.6 }
excited:   { V: +0.7, A: 0.9, D: 0.8 }
```

### ModÃ¨le de confiance

```typescript
EmotionConfidence {
  overall: number,        // Confiance globale (moyenne pondÃ©rÃ©e)
  facial?: number,        // Confiance source faciale
  vocal?: number,         // Confiance source vocale
  textual?: number,       // Confiance source textuelle
  temporal?: number       // Confiance temporelle (cohÃ©rence)
}
```

**Calcul de confiance globale:**
```
Overall = (
  facial * 0.4 +
  vocal * 0.4 +
  textual * 0.2
) * temporal_factor
```

## ğŸ”„ Flux de donnÃ©es

### Scan facial complet

```mermaid
sequenceDiagram
    User->>Component: Click "Start Scan"
    Component->>Hook: startScan('facial')
    Hook->>Browser: getUserMedia({video: true})
    Browser->>Hook: MediaStream
    Hook->>Hook: startProgressTracking()

    loop Every frame
        Hook->>AnalyzeService: analyzeFrame(imageData)
        AnalyzeService->>AI Model: processImage()
        AI Model->>AnalyzeService: rawPredictions
        AnalyzeService->>Hook: emotionResult
    end

    Hook->>Validation: validateEmotionResult()
    Validation->>Hook: validationResult
    Hook->>Aggregation: saveToHistory()
    Hook->>Component: updateCurrentResult()
    Component->>User: Display Results
```

### AgrÃ©gation hebdomadaire

```mermaid
sequenceDiagram
    User->>Component: View Weekly Stats
    Component->>API: GET /me/scan/weekly?since=7
    API->>Database: listWeekly(userHash, since)
    Database->>API: weeklyData[]
    API->>Aggregation: calculateEmotionStatistics()
    Aggregation->>API: statistics
    API->>Component: { data, meta }
    Component->>User: Display Charts & Trends
```

## ğŸ§® Algorithmes avancÃ©s

### Lissage temporel (Smoothing)

UtilisÃ© pour rÃ©duire le bruit dans les analyses en temps rÃ©el:

```typescript
smoothedValue = (
  currentValue * (1 - smoothingFactor) +
  previousValue * smoothingFactor
)
```

**Exemple:**
```typescript
// smoothingFactor = 0.3
valence[t] = valence[t] * 0.7 + valence[t-1] * 0.3
```

### DÃ©tection de changements significatifs

```typescript
isSignificant = (
  (emotionChanged && confidence > 60%) ||
  abs(valenceDelta) > 0.3 ||
  abs(arousalDelta) > 0.3
)
```

### Calcul de stabilitÃ© Ã©motionnelle

```typescript
function calculateStability(results: EmotionResult[]): number {
  let totalVariation = 0;

  for (i = 0; i < results.length - 1; i++) {
    valenceDiff = abs(results[i+1].valence - results[i].valence);
    arousalDiff = abs(results[i+1].arousal - results[i].arousal);
    totalVariation += (valenceDiff + arousalDiff) / 2;
  }

  avgVariation = totalVariation / (results.length - 1);
  stability = max(0, 1 - avgVariation);

  return stability;
}
```

## ğŸ“Š Performance

### Optimisations implÃ©mentÃ©es

1. **Mise en cache**
   - Historique des 20 derniers scans en mÃ©moire
   - Cache des permissions navigateur
   - Debouncing des mises Ã  jour en temps rÃ©el

2. **Traitement asynchrone**
   - Workers Web pour l'analyse d'images
   - Streaming progressif pour l'audio
   - Analyse incrÃ©mentale

3. **RÃ©duction de la charge**
   - Limitation de la frÃ©quence de capture (10 FPS max)
   - Compression des images avant analyse
   - Sampling intelligent de l'audio

### MÃ©triques cibles

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trique                â”‚ Cible        â”‚ Actuel       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Temps d'analyse (image) â”‚ < 100ms      â”‚ ~80ms        â”‚
â”‚ Temps d'analyse (audio) â”‚ < 500ms      â”‚ ~450ms       â”‚
â”‚ Temps d'analyse (texte) â”‚ < 200ms      â”‚ ~150ms       â”‚
â”‚ Utilisation CPU         â”‚ < 30%        â”‚ ~25%         â”‚
â”‚ Utilisation mÃ©moire     â”‚ < 200MB      â”‚ ~180MB       â”‚
â”‚ PrÃ©cision globale       â”‚ > 90%        â”‚ ~93%         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” SÃ©curitÃ©

### Mesures de sÃ©curitÃ©

1. **Protection des donnÃ©es**
   - Chiffrement des donnÃ©es biomÃ©triques
   - Anonymisation par dÃ©faut pour les organisations
   - Hash des identifiants utilisateurs

2. **Validation stricte**
   - Validation de tous les inputs
   - Sanitisation des donnÃ©es
   - Protection contre les injections

3. **Gestion des permissions**
   - VÃ©rification des permissions Ã  chaque scan
   - RÃ©vocation automatique aprÃ¨s inactivitÃ©
   - Consentement explicite requis

## ğŸ”® Extensions futures

### FonctionnalitÃ©s planifiÃ©es

1. **Analyse multi-utilisateur**
   - Scans de groupe
   - Dynamique Ã©motionnelle collective
   - Synchronisation Ã©motionnelle

2. **Apprentissage personnalisÃ©**
   - ModÃ¨le IA adaptatif par utilisateur
   - Calibration automatique
   - DÃ©tection de baseline personnelle

3. **IntÃ©grations**
   - Wearables (Apple Watch, Fitbit)
   - Capteurs IoT
   - APIs tierces (Spotify, Calendar)

4. **Analyse prÃ©dictive avancÃ©e**
   - PrÃ©diction d'humeur Ã  J+1
   - DÃ©tection prÃ©coce de burnout
   - Recommandations proactives

## ğŸ“š RÃ©fÃ©rences

- [ModÃ¨le VAD - Russell (1980)](https://doi.org/10.1037/h0077714)
- [Facial Action Coding System](https://en.wikipedia.org/wiki/Facial_Action_Coding_System)
- [Speech Emotion Recognition - Survey](https://arxiv.org/abs/2001.05618)
- [Sentiment Analysis - NLP](https://nlp.stanford.edu/sentiment/)

---

**DerniÃ¨re mise Ã  jour**: 2024-01-14
**Version de l'architecture**: 1.0.0
