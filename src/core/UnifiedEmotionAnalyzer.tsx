/**
 * üß† ANALYSEUR √âMOTIONNEL UNIFI√â PREMIUM
 * Fusion Hume AI + OpenAI + Analyse comportementale
 * Architecture premium avec fallbacks intelligents
 */

import React, { useState, useEffect, useCallback, useRef } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { 
  Brain, 
  Camera, 
  Mic, 
  MicOff, 
  Play, 
  Pause, 
  Square, 
  RefreshCw,
  Activity,
  Heart,
  Zap,
  Eye,
  AlertTriangle,
  CheckCircle,
  TrendingUp,
  BarChart3
} from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { Alert, AlertDescription } from '@/components/ui/alert';
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';
import { Separator } from '@/components/ui/separator';
import { unifiedEmotionService } from '@/services/UnifiedEmotionService';
import { unifiedMusicService } from '@/services/UnifiedMusicService';
import { EmotionLabel, UnifiedEmotionAnalysis, EmotionVector, SmartRecommendation } from '@/types/unified-emotions';

interface AnalysisSession {
  id: string;
  startTime: Date;
  duration: number;
  analysisCount: number;
  emotions: EmotionLabel[];
  dominantEmotion: EmotionLabel;
  recommendations: SmartRecommendation[];
}

interface UnifiedEmotionAnalyzerProps {
  mode?: 'realtime' | 'session' | 'batch';
  enabledSources?: ('facial' | 'voice' | 'text' | 'biometric')[];
  onAnalysisComplete?: (analysis: UnifiedEmotionAnalysis) => void;
  onRecommendationGenerated?: (recommendations: SmartRecommendation[]) => void;
  className?: string;
}

export const UnifiedEmotionAnalyzer: React.FC<UnifiedEmotionAnalyzerProps> = ({
  mode = 'realtime',
  enabledSources = ['facial', 'voice', 'text'],
  onAnalysisComplete,
  onRecommendationGenerated,
  className = ''
}) => {
  // √âtats principaux
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [currentAnalysis, setCurrentAnalysis] = useState<UnifiedEmotionAnalysis | null>(null);
  const [session, setSession] = useState<AnalysisSession | null>(null);
  const [recommendations, setRecommendations] = useState<SmartRecommendation[]>([]);
  const [error, setError] = useState<string | null>(null);
  const [analysisProgress, setAnalysisProgress] = useState(0);

  // √âtats m√©dia
  const [isCameraEnabled, setIsCameraEnabled] = useState(false);
  const [isMicEnabled, setIsMicEnabled] = useState(false);
  const [permissions, setPermissions] = useState({
    camera: false,
    microphone: false
  });

  // Refs
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const analysisIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const sessionRef = useRef<AnalysisSession | null>(null);

  // V√©rification des permissions
  useEffect(() => {
    const checkPermissions = async () => {
      try {
        if (enabledSources.includes('facial')) {
          const cameraPermission = await navigator.permissions.query({ name: 'camera' as PermissionName });
          setPermissions(prev => ({ ...prev, camera: cameraPermission.state === 'granted' }));
        }
        
        if (enabledSources.includes('voice')) {
          const micPermission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
          setPermissions(prev => ({ ...prev, microphone: micPermission.state === 'granted' }));
        }
      } catch (error) {
        console.warn('Permissions API not supported');
      }
    };

    checkPermissions();
  }, [enabledSources]);

  // Initialisation de la cam√©ra
  const initializeCamera = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'
        }
      });

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        setIsCameraEnabled(true);
        setPermissions(prev => ({ ...prev, camera: true }));
      }
    } catch (error) {
      setError('Impossible d\'acc√©der √† la cam√©ra. V√©rifiez les permissions.');
      console.error('Camera initialization error:', error);
    }
  }, []);

  // Initialisation du microphone
  const initializeMicrophone = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      setIsMicEnabled(true);
      setPermissions(prev => ({ ...prev, microphone: true }));
      
      // Traitement audio en temps r√©el
      const audioContext = new AudioContext();
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);
      
    } catch (error) {
      setError('Impossible d\'acc√©der au microphone. V√©rifiez les permissions.');
      console.error('Microphone initialization error:', error);
    }
  }, []);

  // Capture frame pour analyse faciale
  const captureFrame = useCallback((): string | null => {
    if (!videoRef.current || !canvasRef.current) return null;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');

    if (!ctx) return null;

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0);

    return canvas.toDataURL('image/jpeg', 0.8);
  }, []);

  // Analyse √©motionnelle unifi√©e
  const performUnifiedAnalysis = useCallback(async () => {
    try {
      setAnalysisProgress(0);
      const sources: Array<'facial' | 'voice' | 'text' | 'biometric'> = [];
      const analysisData: Record<string, any> = {};

      // Analyse faciale
      if (enabledSources.includes('facial') && isCameraEnabled) {
        const frame = captureFrame();
        if (frame) {
          sources.push('facial');
          analysisData.facial = { imageData: frame };
        }
      }

      setAnalysisProgress(30);

      // Analyse vocale
      if (enabledSources.includes('voice') && isMicEnabled) {
        sources.push('voice');
        analysisData.voice = { audioBuffer: new ArrayBuffer(0) }; // Simul√©
      }

      setAnalysisProgress(60);

      // Analyse de texte (si disponible)
      if (enabledSources.includes('text')) {
        sources.push('text');
        analysisData.text = { content: 'Analyse comportementale en cours...' };
      }

      setAnalysisProgress(90);

      // Appel au service unifi√©
      const analysis = await unifiedEmotionService.analyzeEmotion({
        sources,
        mode: 'multi_modal',
        includeRecommendations: true,
        context: {
          environment: 'web_interface',
          sessionId: session?.id || 'new_session',
          timestamp: new Date().toISOString()
        },
        ...analysisData
      });

      setCurrentAnalysis(analysis);
      setAnalysisProgress(100);

      // G√©n√©ration de recommandations
      if (analysis) {
        const smartRecommendations = await unifiedEmotionService.generateSmartRecommendations(analysis);
        setRecommendations(smartRecommendations);
        onRecommendationGenerated?.(smartRecommendations);
      }

      // Callbacks
      onAnalysisComplete?.(analysis);

      // Mise √† jour de la session
      if (sessionRef.current) {
        sessionRef.current.analysisCount++;
        sessionRef.current.emotions.push(analysis.primaryEmotion);
        sessionRef.current.dominantEmotion = analysis.primaryEmotion;
        setSession({ ...sessionRef.current });
      }

      setError(null);
    } catch (error) {
      setError('Erreur lors de l\'analyse √©motionnelle. R√©essayez.');
      console.error('Analysis error:', error);
    }
  }, [enabledSources, isCameraEnabled, isMicEnabled, captureFrame, onAnalysisComplete, onRecommendationGenerated, session]);

  // D√©marrage de l'analyse
  const startAnalysis = useCallback(async () => {
    try {
      setIsAnalyzing(true);
      setError(null);

      // Initialisation des sources m√©dia
      if (enabledSources.includes('facial') && !isCameraEnabled) {
        await initializeCamera();
      }

      if (enabledSources.includes('voice') && !isMicEnabled) {
        await initializeMicrophone();
      }

      // Cr√©ation d'une nouvelle session
      const newSession: AnalysisSession = {
        id: `session_${Date.now()}`,
        startTime: new Date(),
        duration: 0,
        analysisCount: 0,
        emotions: [],
        dominantEmotion: 'contentment',
        recommendations: []
      };

      setSession(newSession);
      sessionRef.current = newSession;

      // D√©marrage de l'analyse selon le mode
      if (mode === 'realtime') {
        analysisIntervalRef.current = setInterval(performUnifiedAnalysis, 2000);
      } else {
        await performUnifiedAnalysis();
      }

    } catch (error) {
      setError('Impossible de d√©marrer l\'analyse. V√©rifiez vos permissions.');
      setIsAnalyzing(false);
    }
  }, [mode, enabledSources, isCameraEnabled, isMicEnabled, initializeCamera, initializeMicrophone, performUnifiedAnalysis]);

  // Arr√™t de l'analyse
  const stopAnalysis = useCallback(() => {
    setIsAnalyzing(false);

    if (analysisIntervalRef.current) {
      clearInterval(analysisIntervalRef.current);
      analysisIntervalRef.current = null;
    }

    // Nettoyage des streams m√©dia
    if (videoRef.current?.srcObject) {
      const tracks = (videoRef.current.srcObject as MediaStream).getTracks();
      tracks.forEach(track => track.stop());
    }

    setIsCameraEnabled(false);
    setIsMicEnabled(false);
    setAnalysisProgress(0);
  }, []);

  // Nettoyage lors du d√©montage
  useEffect(() => {
    return () => {
      stopAnalysis();
    };
  }, [stopAnalysis]);

  // Rendu de l'√©tat d'√©motion
  const renderEmotionState = () => {
    if (!currentAnalysis) return null;

    const { primaryEmotion, confidence, emotionVector } = currentAnalysis;
    
    return (
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center space-x-2">
            <Activity className="h-5 w-5 text-primary" />
            <span>√âtat √âmotionnel Actuel</span>
          </CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          <div className="flex items-center justify-between">
            <span className="text-2xl font-bold capitalize">{primaryEmotion}</span>
            <Badge variant="secondary">{Math.round(confidence * 100)}% confiance</Badge>
          </div>
          
          <div className="space-y-2">
            <div className="flex justify-between text-sm">
              <span>Valence</span>
              <span>{Math.round(emotionVector.valence * 100)}%</span>
            </div>
            <Progress value={emotionVector.valence * 100} className="h-2" />
          </div>
          
          <div className="space-y-2">
            <div className="flex justify-between text-sm">
              <span>Activation</span>
              <span>{Math.round(emotionVector.arousal * 100)}%</span>
            </div>
            <Progress value={emotionVector.arousal * 100} className="h-2" />
          </div>
          
          <div className="space-y-2">
            <div className="flex justify-between text-sm">
              <span>Contr√¥le</span>
              <span>{Math.round(emotionVector.dominance * 100)}%</span>
            </div>
            <Progress value={emotionVector.dominance * 100} className="h-2" />
          </div>
        </CardContent>
      </Card>
    );
  };

  // Rendu des recommandations
  const renderRecommendations = () => {
    if (recommendations.length === 0) return null;

    return (
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center space-x-2">
            <TrendingUp className="h-5 w-5 text-primary" />
            <span>Recommandations Intelligentes</span>
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="space-y-3">
            {recommendations.slice(0, 3).map((rec, index) => (
              <div key={index} className="p-3 rounded-lg border bg-muted/30">
                <div className="flex items-start justify-between">
                  <div className="flex-1">
                    <h4 className="font-medium">{rec.title}</h4>
                    <p className="text-sm text-muted-foreground mt-1">{rec.description}</p>
                  </div>
                  <Badge variant={rec.priority === 'high' ? 'destructive' : rec.priority === 'medium' ? 'default' : 'secondary'}>
                    {rec.category}
                  </Badge>
                </div>
                {rec.estimatedDuration && (
                  <div className="mt-2 text-xs text-muted-foreground">
                    Dur√©e estim√©e: {rec.estimatedDuration} min
                  </div>
                )}
              </div>
            ))}
          </div>
        </CardContent>
      </Card>
    );
  };

  return (
    <div className={`space-y-6 ${className}`}>
      {/* Interface de contr√¥le */}
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center space-x-2">
            <Brain className="h-6 w-6 text-primary" />
            <span>Analyseur √âmotionnel Unifi√©</span>
            <Badge variant="secondary">Premium</Badge>
          </CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          {/* Sources d'analyse */}
          <div className="flex flex-wrap gap-2">
            {enabledSources.includes('facial') && (
              <Badge variant={isCameraEnabled ? 'default' : 'outline'} className="flex items-center space-x-1">
                <Camera className="h-3 w-3" />
                <span>Analyse Faciale</span>
              </Badge>
            )}
            
            {enabledSources.includes('voice') && (
              <Badge variant={isMicEnabled ? 'default' : 'outline'} className="flex items-center space-x-1">
                <Mic className="h-3 w-3" />
                <span>Analyse Vocale</span>
              </Badge>
            )}
            
            {enabledSources.includes('text') && (
              <Badge variant="default" className="flex items-center space-x-1">
                <Eye className="h-3 w-3" />
                <span>Analyse Comportementale</span>
              </Badge>
            )}
          </div>

          {/* Contr√¥les */}
          <div className="flex items-center space-x-2">
            {!isAnalyzing ? (
              <Button onClick={startAnalysis} className="flex items-center space-x-2">
                <Play className="h-4 w-4" />
                <span>D√©marrer l'Analyse</span>
              </Button>
            ) : (
              <Button onClick={stopAnalysis} variant="destructive" className="flex items-center space-x-2">
                <Square className="h-4 w-4" />
                <span>Arr√™ter</span>
              </Button>
            )}
            
            {mode === 'session' && (
              <Button onClick={performUnifiedAnalysis} variant="outline" disabled={isAnalyzing}>
                <RefreshCw className="h-4 w-4" />
              </Button>
            )}
          </div>

          {/* Barre de progression */}
          {isAnalyzing && analysisProgress > 0 && (
            <div className="space-y-2">
              <div className="flex justify-between text-sm">
                <span>Analyse en cours...</span>
                <span>{analysisProgress}%</span>
              </div>
              <Progress value={analysisProgress} className="h-2" />
            </div>
          )}

          {/* Erreurs */}
          {error && (
            <Alert variant="destructive">
              <AlertTriangle className="h-4 w-4" />
              <AlertDescription>{error}</AlertDescription>
            </Alert>
          )}
        </CardContent>
      </Card>

      {/* Flux vid√©o (cach√©) */}
      <div className="hidden">
        <video ref={videoRef} autoPlay muted playsInline />
        <canvas ref={canvasRef} />
      </div>

      {/* R√©sultats d'analyse */}
      <Tabs defaultValue="emotion" className="w-full">
        <TabsList className="grid w-full grid-cols-3">
          <TabsTrigger value="emotion">√âtat √âmotionnel</TabsTrigger>
          <TabsTrigger value="recommendations">Recommandations</TabsTrigger>
          <TabsTrigger value="session">Session</TabsTrigger>
        </TabsList>
        
        <TabsContent value="emotion" className="space-y-4">
          {renderEmotionState()}
        </TabsContent>
        
        <TabsContent value="recommendations" className="space-y-4">
          {renderRecommendations()}
        </TabsContent>
        
        <TabsContent value="session" className="space-y-4">
          {session && (
            <Card>
              <CardHeader>
                <CardTitle>Session d'Analyse</CardTitle>
              </CardHeader>
              <CardContent className="space-y-4">
                <div className="grid grid-cols-2 gap-4">
                  <div>
                    <div className="text-sm text-muted-foreground">Analyses effectu√©es</div>
                    <div className="text-2xl font-bold">{session.analysisCount}</div>
                  </div>
                  <div>
                    <div className="text-sm text-muted-foreground">√âmotion dominante</div>
                    <div className="text-2xl font-bold capitalize">{session.dominantEmotion}</div>
                  </div>
                </div>
                
                {session.emotions.length > 0 && (
                  <div>
                    <div className="text-sm text-muted-foreground mb-2">√âvolution √©motionnelle</div>
                    <div className="flex flex-wrap gap-1">
                      {session.emotions.map((emotion, i) => (
                        <Badge key={i} variant="outline" className="text-xs">
                          {emotion}
                        </Badge>
                      ))}
                    </div>
                  </div>
                )}
              </CardContent>
            </Card>
          )}
        </TabsContent>
      </Tabs>
    </div>
  );
};

export default UnifiedEmotionAnalyzer;